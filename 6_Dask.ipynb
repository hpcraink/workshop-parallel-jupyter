{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "106f1e07-a319-4d03-88a9-f621ca802319",
   "metadata": {},
   "source": [
    "<img src=\"images/bwHPC_Logo_cmyk.svg\" width=\"200\" /> <img src=\"images/HochschuleEsslingen_Logo_RGB_DE.png\" width=\"200\" /> <img src=\"images/Konstanz_Logo.svg\" width=\"200\" /> <img src=\"images/KIT_Logo.png\" width=\"200\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bba9f69d-37f4-4bd2-add9-1fb377df269c",
   "metadata": {},
   "source": [
    "# Dask\n",
    "Dask builds on proven modules and extends them with options for massive parallelization. For example, several NumPy arrays or Pandas data frames can be combined in corresponding Dask objects and made available for parallel operations. The Dask objects provide large parts of the well-known API (identical to NumPy arrays or Pandas data frames).\n",
    "\n",
    "Dask can also store data in objects whose size exceeds the available memory. To do this, Dask stores parts of the data in an available file system. Dask can therefore be used to process data volumes that are actually too large for Pandas or NumPy. However, if only a small amount of data needs to be processed/analyzed, the overhead required by Dask can lead to a slowdown compared to pure NumPy/Pandas objects.\n",
    "\n",
    "![image](images/Dask_Scale.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79069453-8eba-4f9e-9d7c-9e547c71adbb",
   "metadata": {},
   "source": [
    "## Dask Dashboard\n",
    "\n",
    "An overview of the parallel processes started by Dask and the utilization of the resources reserved via Dask can be viewed via the Dask Dashboard. The client object from the dask.distributed module enables a Dask dashboard to be started. If the initialized client object is output, the output contains a URL under which the started dashboard can be accessed.\n",
    "\n",
    "If Jupyter version 3.0 is installed or Node.js (version >= 12.0.0) and npm are also installed, the dask-labextensions plugin can be installed in Jupyter as an alternative to manual use. This ensures that the Dask dashboard is integrated into the Jupyter interface. A new \"Dask\" button is then available on the left-hand side. This can be used to access the Dask dashboard without having to call up a separate URL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56ff6906-cf60-4a98-acc8-6dbc27af1226",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask.distributed import Client\n",
    "client = Client(processes=False, threads_per_worker=4,\n",
    "                n_workers=1, memory_limit='2GB')\n",
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "673fecd4-19ff-4c56-a75a-f7855f0383aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "client.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b54da4cf",
   "metadata": {},
   "source": [
    "The dask-labextensions plugin does not currently work with dask-mpi on the bwUniCluster. Alternatively, the URL of the dashboard can be used directly as described above. To do this, the port from the URL must be forwarded from the cluster to the outside via ssh. This can be done locally on the computer being used in a console using the following command. The port and IP of the Jupyter compute node can be taken from the dashboard URL.\n",
    "\n",
    "```bash\n",
    "ssh -N -L <Port>:<Jupyter-Compute-Node>:<Port> <university abbreviation>_<User-ID>@bwunicluster.scc.kit.edu\n",
    "```\n",
    "\n",
    "Example:\n",
    "```bash\n",
    "ssh -N -L 8787:10.0.1.112:8787 es_pkoester@bwunicluster.scc.kit.edu\n",
    "```\n",
    "\n",
    "After executing the ssh port forwarding, the Dask dashboard can be called up on the local computer at\n",
    "\n",
    "```bash\n",
    "http://localhost:<Port>/status\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f8c89e3-065b-4dbc-82ab-225984e5ca74",
   "metadata": {},
   "source": [
    "## Dask Array\n",
    "\n",
    "Dask Array coordinates several NumPy arrays and distributes them across the available resources. This allows operations to be carried out across multiple threads, processes or even nodes. Which operations are possible (which parts of the NumPy Array API are also offered by Dask Array) can be found in the documentation: https://docs.dask.org/en/latest/array-api.html.\n",
    "\n",
    "Further examples of Dask Array: https://mybinder.org/v2/gh/dask/dask-examples/main?urlpath=lab/tree/array.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2814e04-b220-4a28-bdbf-67872d154bc5",
   "metadata": {},
   "source": [
    "## Dask Dataframe\n",
    "\n",
    "What Dask Array is for NumPy arrays (see above), Dask Dataframe is for Pandas Dataframe. The operations possible on a Dask Dataframe can be found in the documentation: https://docs.dask.org/en/latest/dataframe-api.html.\n",
    "\n",
    "A general overview of useful and less useful ways of using a Dask Dataframe can be found at https://docs.dask.org/en/latest/dataframe.html."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f24fb48",
   "metadata": {},
   "source": [
    "## Dask and SLURM\n",
    "\n",
    "In order to use Dask in combination with SLURM (the bwUniCluster job scheduler), either the SLURMCluster class from the dask_jobqueue module or the dask-mpi program is required.\n",
    "\n",
    "The module dask-mpi is required for the following exercises. dask_jobqueue is therefore only described in basic terms (the environment created in \"2_Fundamentals\" was only prepared for dask-mpi: the exercises below can therefore only be carried out with dask-mpi).\n",
    "\n",
    "### dask_jobqueue\n",
    "\n",
    "__IMPORTANT: dask_jobqueue assumes a one-to-one relationship between job and node. This means that exactly one node is reserved and used per job. If several nodes are required, dask_jobqueue ensures that a corresponding number of jobs are submitted. This leads to two fundamental problems on the bwUniCluster. Firstly, several jobs are scheduled independently of one another. Each job therefore has its own start time. It is only with a lot of luck that all the required resources are available at the same time. On the other hand, the cpu queue allows more than one node to be reserved per job. If this queue is used together with dask_jobqueue, dask_jobqueue sets up a separate job for each required node, which reserves two nodes each, of which dask_jobqueue then only uses one.__\n",
    "\n",
    "Conclusion:\n",
    "- in order to have several nodes available at the same time, bwUniCluster provides a job in a queue with several nodes per job\n",
    "- dask_jobqueue requires that only one node is used per job\n",
    "- dask-mpi should be used instead of dask_jobqueue\n",
    "\n",
    "In order for dask_jobqueue to be available, both dask and dask_jobqueue must be installed in the respective environment:\n",
    "\n",
    "```bash\n",
    "python3 -m pip install dask_jobqueue dask\n",
    "```\n",
    "\n",
    "If the IPython kernel from a correspondingly extended environment is registered in Jupyter, it can be selected when starting a new notebook. The SLURMCluster class can then be imported into the notebook and used to create a SLURM job configuration.\n",
    "\n",
    "Which queues are available for such a configuration on the bwUniCluster and what properties they have can be found in the documentation at\n",
    "\n",
    "https://wiki.bwhpc.de/e/BwUniCluster3.0/Running_Jobs#Queues_on_bwUniCluster_3.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e78deda5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask_jobqueue import SLURMCluster\n",
    "cluster = SLURMCluster(\n",
    "    queue='cpu',            # queue cpu allows up to 20 nodes per job \n",
    "    cores=192,              # a node that has queue cpu has 96 cores => two nodes are required for  cores\n",
    "    memory=\"380GB\",       # maximum available memory per node in queue cpu\n",
    "    local_directory='/tmp', # data should be written locally in the node and not to the central file system via the network\n",
    "    walltime='00:30:00',    # nodes should be reserved for half an hour\n",
    "    interface='ib0'         # we want to use fast Infiniband for network communication in the cluster\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ee2daed",
   "metadata": {},
   "source": [
    "The actual job is then started based on the configuration using the scale method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca3fa928",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster.scale(jobs=1) # when starting the configuration, several jobs can be started simultaneously (this makes it possible to reserve several nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3466d918-f30c-48e1-9bcc-ecbb3e65c746",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask.distributed import Client\n",
    "client = Client(cluster)\n",
    "client # contains information on the started cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cbbbdc5-efa0-496e-9577-edcff4c11fdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "client.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbd6dd61-188d-49d1-af83-c2cc6f500603",
   "metadata": {
    "tags": []
   },
   "source": [
    "### dask-mpi\n",
    "\n",
    "The dask-mpi application enables you to start a dask cluster via MPI. This makes it possible to reserve several nodes with just one job. This also makes it possible to use queues that require more than one node per job. It also ensures that all required nodes are available at the same time (since they were requested via the same job).\n",
    "\n",
    "#### Environment\n",
    "\n",
    "The environment created in the \"2_Basics\" notebook is required for the following examples. This environment must be selected for this notebook via the corresponding kernel.\n",
    "\n",
    "So that the environment created in the notebook \"2_Basics\" can be quickly copied to the nodes used, it should be packed in an archive (the following command must be executed in the terminal File->New->Terminal):\n",
    "\n",
    "```bash\n",
    "tar -zcvf ~/miniconda3/envs/python_workshop_env.gz -C ~/miniconda3/envs/ python_workshop_env/\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d6f5d06-cc0a-4e18-a1d4-98282f18ecac",
   "metadata": {},
   "source": [
    "#### sbatch and job script\n",
    "\n",
    "To start a dask cluster via dask-mpi, a job script is required. This is started later via sbatch. Sbatch ensures that the required number of nodes is reserved (this also specifies how many tasks should be started and how they should be distributed across the nodes). Once the requested nodes are available, sbatch executes the script passed on the first of the reserved nodes. In this script, the required data can then be copied to the individual nodes (via separate jobs that are started via srun; local data can be read in more quickly than accessing the central file system). Finally, the script executes a call to mpirun. Dask-mpi is started n times via mpirun. n should be equal to the number of workers required plus one (for the scheduler). The number n must match the number of tasks configured via sbatch.\n",
    "\n",
    "#### Number of processes per node and number of threads per process:\n",
    "\n",
    "The number of threads per process per node multiplied by the number of processes should equal the sum of the available cores. This is the only way to ensure that all threads have a core available and are not slowed down by other threads. However, if individual tasks involve waiting times (e.g. waiting for file I/O or waiting for results from other tasks), it may be better to plan for more parallel tasks (processes or threads) than cores are available.\n",
    "\n",
    "Information about the queues: https://wiki.bwhpc.de/e/BwUniCluster3.0/Running_Jobs#Queues_on_bwUniCluster_3.0\n",
    "\n",
    "Information about the hardware per node: https://wiki.bwhpc.de/e/BwUniCluster3.0/Hardware_and_Architecture\n",
    "\n",
    "If numerical libraries are used predominantly, a high number of threads per process makes sense, as these libraries (Numpy, Pandas, ...) are implemented in such a way that they are not slowed down by Python's Global Interpreter Lock (GIL). They are usually written in C and only offer an interface for access from Python. At the same time, they benefit from the shared use of the same data within a process (no interprocess communication between threads in the same process necessary).\n",
    "\n",
    "If algorithms written mainly in Python are executed, many processes with few or even just one thread per process are a good idea, as the GIL prevents parallel execution with multiple threads in one process.\n",
    "\n",
    "Mixtures of numerical libraries and algorithms implemented in Python require a more balanced ratio between processes and threads."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16e5c0d5-64e5-4f97-b5d2-d0994d88b6e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "## For reservation queue:\n",
    "##  - multi, count_nodes must be at least 2\n",
    "##  - single, count_nodes must be exactly 1\n",
    "count_nodes = 2\n",
    "queue = \"cpu\"\n",
    "\n",
    "count_worker_per_node = 2     # the scheduler is started on the first node => the first node provides one less worker\n",
    "count_threads_per_worker = 20 # count_worker_per_node * count_threads_per_worker should correspond to the number of cores available per node (see above)\n",
    "time = \"30:00\"                # 30 minutes of runtime\n",
    "mem = \"90000mb\"\n",
    "tmp_envs_dir = f\"$TMP/envs\"   # $TMP refers to a local directory for each node and job (/scratch/slurm_tmpdir/job_<job-id>)\n",
    "tmp_dask_dir = f\"$TMP/dask\"   # Dask should swap data under $TMP if there is not enough memory\n",
    "\n",
    "scheduler_file = os.path.expanduser(\"~/dask-scheduler.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fb6336d-1ecc-40f5-b186-1cadeb814263",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_file = os.path.expanduser(\"~/job_dask_mpi.sh\")\n",
    "\n",
    "f = open(job_file, \"w\") # create a new script that can then be sent via sbatch\n",
    "f.write(f\"\"\"#!/bin/bash -l\n",
    "# -l is used to adopt the settings of the bashrc (required for conda)\n",
    "\n",
    "# Variable to go through each node reserved via sbatch individually in a for loop\n",
    "NODES=$(scontrol show hostname | cat)\n",
    "DASK_HOSTS=\"\"\n",
    "for NODE in $NODES; do\n",
    "    # In single queues the node list required for mpirun is missing,\n",
    "    # so we use a self-created host list.\n",
    "    # The double curly brackets are the escape sequence for single curly brackets\n",
    "    # within a Python format string. DASK_HOSTS+=\"${{NODE}},\"\n",
    "\n",
    "    # start a job per node using srun and save data locally in the node under $TMP\n",
    "    # the \"&\" at the end ensures that the srun is executed in parallel in the background\n",
    "    # the \"\\\" at the end of the line masks the target end (the next line still belongs to the current line)\n",
    "    # rm -rf deletes a directory\n",
    "    # mkdir creates a directory\n",
    "    # cp copies a file\n",
    "    # tar unpacks the file\n",
    "    # the \"&&\" between the individual commands ensures that the following commands are only executed\n",
    "    # if the previous command was successful (it did not return an error)\n",
    "    srun -N 1 -n 1 -w $NODE /bin/bash -c \"\\\n",
    "      rm -rf {tmp_envs_dir} && \\\n",
    "      rm -rf {tmp_dask_dir} && \\\n",
    "      mkdir -p {tmp_envs_dir} && \\\n",
    "      mkdir -p {tmp_dask_dir} && \\\n",
    "      cp ~/miniconda3/envs/python_workshop_env.gz {tmp_envs_dir} && \\\n",
    "      tar -zxf {tmp_envs_dir}/python_workshop_env.gz --directory {tmp_envs_dir} \\\n",
    "    \" &\n",
    "done\n",
    "\n",
    "# wait for all commands started in parallel\n",
    "\n",
    "wait\n",
    "\n",
    "# Activate the local environment (does not have to be done on every node, as the\n",
    "# corresponding environment variables are adopted via mpirun)\n",
    "\n",
    "conda activate {tmp_envs_dir}/python_workshop_env\n",
    "\n",
    "# starts the workers and a scheduler on the nodes\n",
    "# --map-by core:PE=n: each process should be assigned n cores\n",
    "# -np x: x = number of workers + 1 for scheduler (x must be equal to --ntasks when executing sbatch)\n",
    "# -host=$DASK_HOSTS: hosts on which processes should be started\n",
    "# --scheduler-file: as soon as all workers are started, the scheduler writes the connection information of the dask cluster to this file)\n",
    "# --interface='ib0': we use Infiniband for communication between the nodes\n",
    "# --local-directory={tmp_dask_dir}: if dask has to outsource data due to a lack of memory, the local file system of the respective node should be used for this\n",
    "# --worker-class=distributed.Worker: no monitoring nanny process per worker process\n",
    "# --nthreads: threads per worker\n",
    "# --name: prefix for naming the workers in this job\n",
    "# --dashboard-address: the port under which the dashboard can be reached (8787 is actually the Default value, but in the current development state this is not set automatically)\n",
    "mpirun --map-by core:PE={count_threads_per_worker} \\\n",
    "    -np {count_nodes * count_worker_per_node} \\\n",
    "    -host=$DASK_HOSTS \\\n",
    "    dask-mpi \\\n",
    "    --scheduler-file {scheduler_file} \\\n",
    "    --interface='ib0' \\\n",
    "    --local-directory={tmp_dask_dir} \\\n",
    "    --worker-class=distributed.Worker \\\n",
    "    --nthreads={count_threads_per_worker} \\\n",
    "    --name base \\\n",
    "    --dashboard-address=8787\"\"\")\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8996d098-d4e0-459e-b59b-46ab4edcd920",
   "metadata": {},
   "outputs": [],
   "source": [
    "# how many nodes are currently freely available per queue\n",
    "# can also be issued in a terminal (File->New->Terminal) outside the Jupyter Notebook as the command \"sinfo_t_idle\"\n",
    "os.system(\"sinfo_t_idle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86dbe946-826d-4a38-ba22-f0483cf27d06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rm: delete the ~/dask-scheduler.json file: as soon as the file is back, the requested Dask cluster is started\n",
    "# sbatch: reserves the necessary resources (nodes) in the specified queue and starts the script ~/job_dask_mpi.sh on the first of the nodes\n",
    "os.system(f\"rm -f {scheduler_file} && \\\n",
    "            sbatch \\\n",
    "            -p {queue} \\\n",
    "            --nodes={count_nodes} \\\n",
    "            --ntasks={count_nodes * count_worker_per_node} \\\n",
    "            --ntasks-per-node={count_worker_per_node} \\\n",
    "            --time={time} \\\n",
    "            --mem={mem} \\\n",
    "            {job_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cf484ad-3205-4111-b98b-abfb3294db1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Has the queueing system provided a tentative start time of the job?\n",
    "os.system(\"squeue --start\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3c391c8-4548-4fa2-bd5b-24aaf3c3103d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Which resources are requested for our user?\n",
    "# Shows one line per job with which resources were requested.\n",
    "#   ST: Status\n",
    "#   PD: Pending, resources have been requested but are not yet available\n",
    "#   R: Running, resources are available\n",
    "#   CG: Completing, job is finished/aborted, but individual processes are still running (which are still being finished or aborted)\n",
    "#   other status codes: https://curc.readthedocs.io/en/latest/running-jobs/squeue-status-codes.html\n",
    "#   TIME: how long have the resources been used by us\n",
    "#   NODES: number of reserved nodes\n",
    "#   NODELIST: which nodes are reserved\n",
    "# The name of the nodes is given with a prefix (is the same for each node)\n",
    "# followed by the numbering of the individual nodes in square brackets.\n",
    "# A hyphen between two numbers in the square brackets means that all\n",
    "# numbers between the two given are reserved for us.\n",
    "# A comma between two numbers means that the two numbers are reserved for us.\n",
    "# Examples:\n",
    "#   uc3n[001-003] indicates that uc3n001, uc3n002 and uc3n003 have been reserved\n",
    "#   uc3n[001,003] indicates that uc3n001 and uc3n003 have been reserved\n",
    "os.system(\"squeue\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f06cb2ac-7a8d-4030-b500-26de8a86187f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, time as t\n",
    "\n",
    "# Wait until the scheduler_file (~/dask-scheduler.json) is available\n",
    "# (Will be written by the dask-scheduler as soon as worker has been started and is ready=\n",
    "while not os.path.isfile(scheduler_file):\n",
    "    t.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e42aac6c-6ba2-4c1a-b569-0343e04b2cc1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Current status and error messages of the SLURM job may be retrieved from the slurm-<JOBID>.out file:\n",
    "jobid = 22439085      # PLEASE ADAPT THE JOBID as described above\n",
    "cwd = os.getcwd()\n",
    "f = open(cwd + \"/slurm-\" + str(jobid) + \".out\",\"r\")\n",
    "lines = f.readlines()\n",
    "display(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8f377a3-0af2-46f6-be7a-21bc0f87aeee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask\n",
    "from dask.distributed import Client\n",
    "\n",
    "# We can use a client object to connect the current Jupyter notebook to the created Dask cluster.\n",
    "# To do this, we use the ~/dask-scheduler.json file. This is where the scheduler's IP and port are stored.\n",
    "# (instead of from a Jupyter notebook, this can also be done from a Python script, for example)\n",
    "client = Client(scheduler_file=scheduler_file)\n",
    "\n",
    "# if dask has to swap out data due to a lack of memory,\n",
    "# the local file system of the respective node should be used\n",
    "dask.config.set({'temporary_directory': tmp_dask_dir})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0894c66c-504d-49c8-ab98-9e81f2f93d30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's show the client (which contains information on the scheduler and the workers)\n",
    "client"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb826ce4-17d8-4965-b8ff-2a29b60a783a",
   "metadata": {},
   "source": [
    "### Enlarge Dask cluster later\n",
    "\n",
    "Additional workers can be created with a separate job and added to the scheduler from a previous job. The scheduler-json file is also used for this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e16476e3-cdd0-4387-993b-d95239e02b9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_file = os.path.expanduser(\"~/job_dask_mpi_2.sh\")\n",
    "\n",
    "# A script to enlarge an existing Dask -Cluster\n",
    "f = open(job_file, \"w\")\n",
    "f.write(f\"\"\"#!/bin/bash -l\n",
    "NODES=$(scontrol show hostname | cat)\n",
    "DASK_HOSTS=\"\"\n",
    "for NODE in $NODES\n",
    "do\n",
    "    DASK_HOSTS+=\"${{NODE}},\"\n",
    "    \n",
    "    srun -N 1 -n 1 -w $NODE /bin/bash -c \"\\\n",
    "        rm -rf {tmp_envs_dir} && \\\n",
    "        rm -rf {tmp_dask_dir} && \\\n",
    "        mkdir -p {tmp_envs_dir} && \\\n",
    "        mkdir -p {tmp_dask_dir} && \\\n",
    "        cp ~/miniconda3/envs/python_workshop_env.gz {tmp_envs_dir} && \\\n",
    "        tar -zxf {tmp_envs_dir}/python_workshop_env.gz --directory {tmp_envs_dir} \\\n",
    "        \" &\n",
    "done\n",
    "\n",
    "wait\n",
    "\n",
    "conda activate {tmp_envs_dir}/python_workshop_env\n",
    "\n",
    "# Since an existing Dask-Cluster shall be enlarged:\n",
    "# --no-scheduler: do not create a new scheduler, but rather register the works with the Scheduler specified in the $scheduler_file\n",
    "mpirun --map-by core:PE={count_threads_per_worker} \\\n",
    "       -np {count_nodes * count_worker_per_node} \\\n",
    "       -host=$DASK_HOSTS \\\n",
    "       dask-mpi \\\n",
    "       --scheduler-file {scheduler_file} \\\n",
    "       --interface='ib0' \\\n",
    "       --local-directory={tmp_dask_dir} \\\n",
    "       --worker-class=distributed.Worker \\\n",
    "       --nthreads={count_threads_per_worker} \\\n",
    "       --no-scheduler \\\n",
    "       --name expansion\"\"\")\n",
    "f.close()\n",
    "\n",
    "# Reserve another node in the batch system and assign to the cluster\n",
    "os.system(f\"sbatch \\\n",
    "            -p {queue} \\\n",
    "            --nodes={count_nodes} \\\n",
    "            --ntasks={count_nodes * count_worker_per_node} \\\n",
    "            --ntasks-per-node={count_worker_per_node} \\\n",
    "            --time={time} \\\n",
    "            --mem={mem} \\\n",
    "            {job_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11ae8515-c194-40c2-a847-54f13cf5595a",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.system(\"squeue\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "028f63e4-a29f-47c6-8eac-4dfbc540eca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wait until workers are available (for the first worker in the second job)\n",
    "client.wait_for_workers((count_nodes * count_worker_per_node * 2) -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a268b59-6895-4c61-90b6-655214a69809",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Again show information on the workers\n",
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9859cc17-cef5-4f63-96a7-904ea4c6955b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# instead of connecting a client to a Dask cluster via the json file, an IP address can also be used\n",
    "from distributed import Client\n",
    "# for this, the IP and PORT for registration must be known (e.g. from the slurm-<JOBID>.out file)\n",
    "client = Client('172.26.20.82:37153')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f89d002c-bb8c-4ede-b4a8-613027e82b90",
   "metadata": {},
   "outputs": [],
   "source": [
    "client"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cde158da-65e4-4981-95a7-8d126a175220",
   "metadata": {},
   "source": [
    "## Example Dask Array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6bf23eb-14de-482f-9ddc-b9cef3a847cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.array as da\n",
    "\n",
    "# Creates an array with 100,000 rows and 100,000 columns.\n",
    "# Each element contains a random value from the interval [0.0, 1.0).\n",
    "#\n",
    "# The array is divided into individual chunks. Each chunk is created by\n",
    "# a separate task. This allows Dask to distribute each chunk to\n",
    "# another worker.\n",
    "# The tasks are only executed when the array is being worked on.\n",
    "# x therefore does not contain a finished array, but only the tasks\n",
    "# that are necessary to create the array.\n",
    "# Instead of specifying the maximum chunk size in MiB, the\n",
    "# number of elements per chunk can also be defined (see\n",
    "# https://docs.dask.org/en/latest/array-chunks.html).\n",
    "x = da.random.random((100000,100000), chunks=\"100 MiB\")\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3d1b62f-8380-4f61-a932-3f693ea52e2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A calculation operation on a Dask array initially only creates tasks.\n",
    "# These are only executed when a result is requested.\n",
    "y = (x + x.T) - x.mean(axis=0)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afa02b1c-2f30-46d2-aacf-b7ec2aca1e21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The compute() method requests a specific result. By calling this method, the planned tasks are executed.\n",
    "y.sum().compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2189e13-d557-4c29-8508-0587fa44bbbe",
   "metadata": {},
   "source": [
    "## Example Dask DataFrame and Scikit-Learn\n",
    "\n",
    "Based on https://github.com/rikturr/high-performance-jupyter (MIT-License)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4b44b90-0bbf-428a-bd59-64300d7f512a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# %%time measures the time that a cell in the notebook needs for execution\n",
    "# %%time must be the first line in the cell\n",
    "\n",
    "import dask.dataframe as dd\n",
    "\n",
    "# erstellt Tasks um ~8 GB Daten aus einem s3 Bucket zu laden und als Dataframe einzulesen\n",
    "#taxi = dd.read_csv(\n",
    "#    's3://nyc-tlc/trip data/yellow_tripdata_2019-*.csv',\n",
    "#    assume_missing=True, # beim Einlesen werden alle Ints zu Floats. Dies erlaubt fehlende Werte\n",
    "#    parse_dates=['tpep_pickup_datetime', 'tpep_dropoff_datetime'], # interpretiert diese Spalten als Datum\n",
    "#    storage_options={'anon': True}, # für S3: keine Authentifizierung für diesen Bucket nötig\n",
    "#)\n",
    "## S3 requires an account for AWS; direct access therefore not possible\n",
    "## Please use the provided parquet-File (see below)\n",
    "\n",
    "taxi = dd.read_parquet(\n",
    "    './files/green_tripdata_2023-01.parquet',\n",
    "    engine='pyarrow'\n",
    ")\n",
    "#df = pd.read_parquet('./files/green_tripdata_2023-01.parquet', engine='pyarrow')\n",
    "taxi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06b7425c-4716-4206-919f-87f21103056b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# both following lines execute the tasks contained in \"taxi\",\n",
    "# to use their results for further operations\n",
    "# => Reading into the data frame is executed twice!\n",
    "\n",
    "print(f\"Number of rows: {len(taxi)}\") #Rows of all data records together\n",
    "print(f\"Size in GB: {taxi.memory_usage(deep=True).sum().compute() / 1e9}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "185fd416-8b12-47c6-945a-0515847cec77",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask.distributed import wait\n",
    "\n",
    "# persist() executes all planned tasks in the background (asynchronously) and returns the result\n",
    "# we therefore replace the tasks here with the finished data frame\n",
    "taxi = taxi.persist()\n",
    "# wait() waits for the tasks started in the background\n",
    "_ = wait(taxi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8778954e-89be-4917-9aff-fda7d13cbf7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# len() and memory_usage() are significantly faster when working on the persisted\n",
    "# result of the tasks\n",
    "print(f\"Number of rows: {len(taxi)}\") #Rows of all records together\n",
    "print(f\"Size in GB: {taxi.memory_usage(deep=True).sum().compute() / 1e9}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09b12289-cb5c-4022-9fb1-485d3a71df2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_feat = [\n",
    "    'pickup_weekday', \n",
    "    'pickup_hour', \n",
    "    'pickup_week_hour', \n",
    "    'pickup_minute', \n",
    "    'passenger_count',\n",
    "]\n",
    "categorical_feat = [\n",
    "    'PULocationID', \n",
    "    'DOLocationID',\n",
    "]\n",
    "features = numeric_feat + categorical_feat\n",
    "y_col = 'high_tip'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51bcdfff-4526-4cd2-8527-04a60fa71cd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_df(df: dd.DataFrame) -> dd.DataFrame:\n",
    "    '''\n",
    "    Generate features from a raw taxi dataframe.\n",
    "    '''\n",
    "    df = df[df.fare_amount > 0]  # Only the lines, that contain non-zeros (to avoid division-by-zero)\n",
    "    df['tip_fraction'] = df.tip_amount / df.fare_amount\n",
    "    df[y_col] = (df['tip_fraction'] > 0.2) # If tip_amount / fare_amount > 0.2, then high_tip = true\n",
    "    \n",
    "    df['pickup_weekday'] = df.lpep_pickup_datetime.dt.weekday\n",
    "    df['pickup_weekofyear'] = df.lpep_pickup_datetime.dt.isocalendar().week\n",
    "    df['pickup_hour'] = df.lpep_pickup_datetime.dt.hour\n",
    "    df['pickup_week_hour'] = (df.pickup_weekday * 24) + df.pickup_hour\n",
    "    df['pickup_minute'] = df.lpep_pickup_datetime.dt.minute\n",
    "    \n",
    "    # Convert all inputs for the training to floats and set unavailable values to -1\n",
    "    df = df[features + [y_col]].astype(float).fillna(-1)\n",
    "    \n",
    "    return df\n",
    "    \n",
    "taxi = prep_df(taxi)\n",
    "taxi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bf5bbec-5287-4450-a0b2-bd8b8dfb9822",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Task to prepare the data frame (prep_df)\n",
    "taxi = taxi.persist()\n",
    "_ = wait(taxi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3314ae9b-8653-4d44-821a-ce6a19ff794d",
   "metadata": {},
   "outputs": [],
   "source": [
    "taxi.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8390e404-4f6d-4572-9052-6f2d416f7f39",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# describe() generates for each columns a statisctical overview (Min., Max., Quantile, ...)\n",
    "np.round(taxi.describe().compute(), 3).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c43c2121-675d-4181-8401-3678286286a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42\n",
    "\n",
    "taxi_sample = taxi.sample(frac=0.02, replace=False, random_state=seed)\n",
    "taxi_sample = taxi_sample.persist()\n",
    "_ = wait(taxi_sample)\n",
    "\n",
    "len(taxi_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdec68bc-f0b7-4255-80d2-90d35fa59a71",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from dask_ml.compose import ColumnTransformer\n",
    "from dask_ml.preprocessing import StandardScaler, DummyEncoder, Categorizer\n",
    "from dask_ml.model_selection import GridSearchCV\n",
    "\n",
    "seed = 42\n",
    "\n",
    "lr = LogisticRegression(\n",
    "    solver='saga',\n",
    "    penalty='elasticnet', \n",
    "    l1_ratio=0.5,\n",
    "    max_iter=100, \n",
    "    random_state=seed,\n",
    ")\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('categorize', Categorizer(columns=categorical_feat)),\n",
    "    ('onehot', DummyEncoder(columns=categorical_feat)),\n",
    "    ('scale', ColumnTransformer(transformers=[('num', StandardScaler(), numeric_feat)])),\n",
    "    ('clf', lr),\n",
    "])\n",
    "\n",
    "params = {\n",
    "    'clf__l1_ratio': [0.2, 0.3, 0.5, 0.7, 0.9],\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    pipeline, \n",
    "    params,\n",
    "    cv=3, \n",
    "    scoring='accuracy',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1584453-7c18-4820-936b-0d9c488e159d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Before fit() is called, joblib can be told that a Dask cluster is available.\n",
    "# joblib is used by scikit-learn to parallelize. This can be useful if\n",
    "# objects from dask_ml are not already being used.\n",
    "#import joblib            # is needed to connect scikit-learn to the Dask cluster\n",
    "#with joblib.parallel_backend('dask'):\n",
    "# _ = grid_search.fit(taxi_sample[features], taxi_sample[y_col])\n",
    "_ = grid_search.fit(taxi_sample[features], taxi_sample[y_col])\n",
    "\n",
    "grid_search.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85258b57-d9e6-499c-b1e7-b4257f7ed9be",
   "metadata": {},
   "source": [
    "## Functions as tasks\n",
    "\n",
    "With the \"delayed\" decorator, functions can be converted into tasks when called. These tasks are then executed by Dask as soon as a result is requested. Scheduling and executing a task generates overhead. A task should therefore always contain as much computing power as possible. It can be counterproductive to keep tasks as small as possible. The following example is only intended to help you understand tasks. It contains tasks that are too small. If the range() in the for loop is increased, problems quickly arise (Dask generates warnings).\n",
    "\n",
    "Delayed functions are subject to restrictions. For example, they cannot be used in a condition (if or loop condition).\n",
    "\n",
    "More information on delayed: https://docs.dask.org/en/stable/delayed-api.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec017db8-68b1-46d4-b499-0e45d784f66a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.delayed as delayed\n",
    "\n",
    "@delayed\n",
    "def increment(x):\n",
    "    return x + 1\n",
    "\n",
    "@delayed\n",
    "def power2(x):\n",
    "    return x ^ 2\n",
    "\n",
    "@delayed\n",
    "def add(x, y):\n",
    "    return x + y\n",
    "\n",
    "# Generation of 10000 Tasks (each of two Tasks) into a list\n",
    "output = []\n",
    "for x in range(1, 10000):\n",
    "    a = increment(x)\n",
    "    b = power2(x)\n",
    "    c = add(a, b)\n",
    "    output.append(c)\n",
    "\n",
    "# A new task based on the list\n",
    "total = delayed(sum)(output)\n",
    "total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3992d12e-8712-44a3-8141-1daf5fe7eefa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute Tasks\n",
    "res = total.compute()\n",
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5e103bc-5d3e-4f50-a3b6-d154ccf8023c",
   "metadata": {},
   "source": [
    "## Visualization of Dask-Tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cd7e945-1e66-4bba-9e8c-f465b7eb749a",
   "metadata": {},
   "outputs": [],
   "source": [
    "output2 = []\n",
    "# So that the generated graph stays clear: just 10 Iterations\n",
    "for x in range(1, 10):\n",
    "    a = increment(x)\n",
    "    b = power2(x)\n",
    "    c = add(a, b)\n",
    "    output2.append(c)\n",
    "\n",
    "total2 = delayed(sum)(output2)\n",
    "total2.visualize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f53c2d8-0eac-44df-a8f5-18764381fe3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = total2.compute()\n",
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f380296-a467-41b0-8967-cb9d4ee5d84c",
   "metadata": {},
   "source": [
    "## Progress Bar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f27a113-eece-4434-a37f-28b9680bb2e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "client.close() # ProgressBar only works if no Dask cluster is actively connected\n",
    "# if necessary, the cluster job must be terminated so that the ProgressBar is displayed (see Ending jobs below)\n",
    "\n",
    "from dask.diagnostics import ProgressBar\n",
    "\n",
    "with ProgressBar():\n",
    "    res = total.compute()\n",
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22d4476a-c74f-4b46-9c54-7a7fcb2f13c8",
   "metadata": {},
   "source": [
    "## Free Ressources (end Jobs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "064d9720-5955-4310-90c8-05674d6ec7ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If resources are no longer needed, the associated job must be terminated\n",
    "# to release the resources (nodes) again.\n",
    "job_id = 22439198               # PLEASE ADAPT JOB_ID\n",
    "os.system(f\"scancel {job_id}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python_workshop_env",
   "language": "python",
   "name": "python_workshop_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
